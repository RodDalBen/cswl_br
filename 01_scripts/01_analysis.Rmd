---
title: "Cross-situational word learning with Brazilians"
output: html_notebook
author: "Rodrigo Dal Ben"
date: 10/02/2021
---

Last update: 2022-08-31

# Background

#ADD DETAILS
**Analyses reported by**: Dal Ben, R., Souza, D. H. & Hay, J. (under review). Combining statistics: The role of phonotactics on cross-situational word learning. ##### ADD DETAILS HERE ######

**OSF project**: https://osf.io/6fqzg/

**Feedback and suggestions:** <dalbenwork@gmail.com>

# Session info (as of last update)

R version 4.2.1 (2022-06-23)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Monterey 12.5.1

# Load packages

Here we add the option of using `groundhog` (v2.0.1) for reproducing the same R and packages' versions that we used when running the script on our end. To use `groundhog`, turn the switch to `T`. Otherwise, just run the code chunk (switch set to `F`).

```{r}
# should R use groundhog
use_groundhog <- F

# set vector w/ packages
packages = c("tidyverse",
             "tidylog", 
             "boot",
             "gmodels",
             "ggdist",
             "lme4", 
             "brms",
             "sjPlot", 
             "patchwork", 
             "janitor",
             "RColorBrewer", 
             "beepr", 
             "here")

# load packages
if(use_groundhog == T){
  packages_date <- "2022-08-28" 
  library(groundhog) # v2.0.1
  groundhog::groundhog.library(pkg = packages, date = packages_date)
  rm(packages, packages_date, use_groundhog) # clean
}else{
  # if necessary install
  installed_packages <- packages %in% rownames(installed.packages())
  if(any(installed_packages == F)){install.packages(packages[!installed_packages])}
  # load packages
  invisible(lapply(packages, library, character.only = T))
  # clean
  rm(installed_packages, packages, use_groundhog)
}

# avoid scientific notation
options(scipen = 0)
```

# Load data

```{r}
# load 
load(here("02_data/tidy_data_cswl_br.rda"))

# double check sample size (should be 30)
data %>% distinct(p_n_unique) %>% count() # 30 participants

# filter first test trial of each pair for each participant
data_first_trial <- 
  data %>% 
  filter(trial_type == "test cswl") %>%
  group_by(p_n_unique, target_audio_cswl) %>%
  slice_head() %>% # select the first
  ungroup() 
```

# Prepare data

```{r}
# filter test trials, the first trial for each pair, and set index for trials with rt > 3 SDs
sd_comp <- 
  data_first_trial %>% 
  summarise(sd_1 = sd(rt, na.rm = T),
            sd_3 = sd_1*3)

data_clean_test <- 
  data_first_trial %>% 
  filter(rt < mean(rt, na.rm = T) + sd_comp$sd_3) # 16 trials (2%) excluded

## excluded trials summary
data_clean_test %>% distinct(p_n_unique) %>% count() # 30 participants
data_clean_test %>% group_by(p_n_unique) %>% summarise(n_trials = n()) # 12 trials, 1 for each pair
```

# Demographics

```{r}
# summary data
data_clean_test %>% 
  group_by(p_n_unique) %>% 
  slice_head() %>%
  ungroup() %>% 
  summarise(
    n = n(), 
    age_avg = mean(age),
    age_sd = sd(age),
    female = length(which(gender == "female")),
  )
```

# Visualizations

## Summary data

```{r}
# calculating mean for each block
data_summ <- 
  data_clean_test %>% 
  group_by(p_n_unique, stimuli_set_pp) %>% 
  summarise(
    is_correct_avg = mean(is_correct),
    is_correct_sum = sum(is_correct),
    trials_n = 12,
    rt = mean(rt)
    ) %>% 
  ungroup()

# number of trials and proportion
data_summ %>% group_by(stimuli_set_pp) %>% summarise(m = mean(is_correct_sum), sd = sd(is_correct_sum))
data_summ %>% group_by(stimuli_set_pp) %>% summarise(m = mean(is_correct_avg), sd = sd(is_correct_avg))
```

## Mean correct 
## FIX PLOT STYLE

```{r}
# sum
sum_pp_plot <-  
  data_summ %>% 
  ggplot(aes(x = as_factor(""), y = is_correct_sum, color = stimuli_set_pp)) +
  geom_violin(alpha = 0.6) +
  geom_point(position = position_jitterdodge(jitter.width = 0.1, dodge.width = 0.9), 
             alpha = 0.3) + 
  stat_summary(fun.data = "mean_cl_boot", 
               position = position_dodge(width = 0.9)) +
  scale_y_continuous(breaks = seq(0, 12, 1)) +
  geom_hline(yintercept = 6/4, linetype = "dashed") +
  labs(y = "Mean number of correct selections", x = "Phonotactics") +
  theme_bw()
        
sum_pp_plot

# proportions
avg_pp_plot <-  
  data_summ %>% 
  ggplot(aes(x = stimuli_set_pp, y = is_correct_avg)) +
  stat_summary(fun.data = "mean_cl_boot", size = 0.5) +
  ggdist::stat_halfeye(geom = "slab", 
                       justification = -0.1,
                       alpha = 0.4) +
  geom_dotplot(binaxis = "y", 
               stackdir = "down", 
               dotsize = 0.5, 
               alpha = 0.2) + 
  scale_y_continuous(breaks = seq(0, 1, 0.25)) +
  geom_hline(yintercept = 1/4, linetype = "dashed") +
  labs(y = "Mean number of correct selections", x = "Phonotactics") +
  theme_classic(base_size = 10) + 
  theme(legend.position = "")
         
avg_pp_plot

# save tiff
#ggsave(here("03_output_graphics/plot_pp.tiff"), 
#       width = 15, height = 8, units = "cm", dpi = 300)

# save png
#ggsave(here("03_output_graphics/plot_pp.png"), 
#       width = 15, height = 8, units = "cm", dpi = 300)

# extract the stat_summary from the graph
plot_stats <- ggplot_build(sum_pp_plot)$`data`[[2]] # trials
plot_stats <- ggplot_build(avg_pp_plot)$`data`[[2]] # proportions
```

# Statistics

## Descriptive

```{r}
stats_pp_summ <- 
  data_summ %>%
  group_by(stimuli_set_pp) %>% 
  summarise(
    is_corr = mean(is_correct_avg),
    sd = sd(is_correct_avg), 
    ci_low = gmodels::ci(is_correct_avg)[2],
    ci_high = gmodels::ci(is_correct_avg)[3],
    rt_mean = mean(rt)
  )

stats_pp_summ
```

## Inferential

### Frequentist 

```{r}
## random slope and intercept - FAILED TO CONVERGE
#mod0_freq <- 
#  data_clean_test %>% 
#  glmer(is_correct ~ offset(logit(chance_level)) + stimuli_set_pp +
#                (target_visual|p_n_unique),  
#              data = .,
#              family = "binomial")

## random intercept
mod1_pp_freq <- 
  data_clean_test %>% 
  #mutate(stimuli_set_pp = factor(stimuli_set_pp, levels = c("PP+", "PP-"))) %>% # PP+ as baseline
  glmer(is_correct ~ offset(logit(chance_level)) + stimuli_set_pp +
                (1|target_visual) + (1|p_n_unique), 
              data = .,
              family = "binomial")

summary(mod1_pp_freq)
confint(mod1_pp_freq, method = "Wald")
tab_model(mod1_pp_freq, title = "Fixed and random effects for Frequentist analysis [selection ~ chance level + phonotactics + (1|stimuli) + (1|participant)]", show.re.var = T, show.icc = T, show.p = F)#, file = here("03_output_graphics/mod_pp_freq.doc"))
```

### Bayesian

```{r}
mod0_pp_bay <- 
  data_clean_test %>% 
  #mutate(stimuli_set_pp = factor(stimuli_set_pp, levels = c("PP+", "PP-"))) %>% # PP+ as baseline
  brm(is_correct ~ offset(logit(chance_level)) + stimuli_set_pp + (target_visual|p_n_unique),
            data = .,
            family = "bernoulli",
            iter = 4000,
            chains = 4
            )

summary(mod0_pp_bay)
tab_model(mod0_pp_bay, title = "Fixed and random effects Bayesian analysis [selection ~ chance level + phonotactics + (stimuli|participant)]", show.re.var = T, show.icc = T)#, file = here("03_output_graphics/mod_pp_bay.doc"))

# let me know when model is done running
beep(sound = 1, expr = NULL)
```

# THE END 
